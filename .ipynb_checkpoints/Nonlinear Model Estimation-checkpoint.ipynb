{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "iAiHC0sucx23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1473,
     "status": "ok",
     "timestamp": 1627946203177,
     "user": {
      "displayName": "Ying Zhou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHV9f7CxBRGPIo2NDc6TBV5JOSCfiAUOEd5qEa=s64",
      "userId": "01839765169556069563"
     },
     "user_tz": -600
    },
    "id": "iAiHC0sucx23",
    "outputId": "fead39c3-e442-4424-b109-dcba1f958915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import xlsxwriter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import DataPreparation as dpr\n",
    "import Models\n",
    "import benchmarks as bench\n",
    "from MyEstimators import CLS_Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-KNTpyy1cx27",
   "metadata": {
    "id": "-KNTpyy1cx27"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "AccoGDGScx28",
   "metadata": {
    "id": "AccoGDGScx28"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/EQP_Quarterly.xlsx', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3fe178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df['yyyyq'] = df['yyyyq'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b7c7de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = [pd.to_datetime(str(x)[:4]) + pd.offsets.QuarterEnd(int(str(x)[4:])) for x in df['yyyyq']]\n",
    "df = df.set_index('time')\n",
    "df = df.drop(['yyyyq'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "921d563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc['1956-03-31':'2018-12-31']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qDYQVXsycx3A",
   "metadata": {
    "id": "qDYQVXsycx3A"
   },
   "source": [
    "## Add new cay variable and construct X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "PiJh9_Tdcx3B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 325,
     "status": "ok",
     "timestamp": 1627946226981,
     "user": {
      "displayName": "Ying Zhou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHV9f7CxBRGPIo2NDc6TBV5JOSCfiAUOEd5qEa=s64",
      "userId": "01839765169556069563"
     },
     "user_tz": -600
    },
    "id": "PiJh9_Tdcx3B",
    "outputId": "a5536169-27b7-4878-bc9a-20efbbe2eddd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EQP</th>\n",
       "      <th>y_lag</th>\n",
       "      <th>y_2lag</th>\n",
       "      <th>DP</th>\n",
       "      <th>DY</th>\n",
       "      <th>EP</th>\n",
       "      <th>DE</th>\n",
       "      <th>svar</th>\n",
       "      <th>b/m</th>\n",
       "      <th>ntis</th>\n",
       "      <th>...</th>\n",
       "      <th>infl</th>\n",
       "      <th>c</th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>cay</th>\n",
       "      <th>AAA</th>\n",
       "      <th>BAA</th>\n",
       "      <th>rr</th>\n",
       "      <th>rfree</th>\n",
       "      <th>new_cay</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1956-03-31</th>\n",
       "      <td>0.066512</td>\n",
       "      <td>0.047768</td>\n",
       "      <td>0.063101</td>\n",
       "      <td>-3.322576</td>\n",
       "      <td>-3.281965</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>-0.791778</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.509828</td>\n",
       "      <td>0.025245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003717</td>\n",
       "      <td>9.274968</td>\n",
       "      <td>11.074455</td>\n",
       "      <td>9.093439</td>\n",
       "      <td>0.019292</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.075561</td>\n",
       "      <td>0.006350</td>\n",
       "      <td>-0.423108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-06-30</th>\n",
       "      <td>-0.028264</td>\n",
       "      <td>0.066512</td>\n",
       "      <td>0.047768</td>\n",
       "      <td>-3.333030</td>\n",
       "      <td>-3.269151</td>\n",
       "      <td>-2.575525</td>\n",
       "      <td>-0.757505</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.531077</td>\n",
       "      <td>0.026695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.272498</td>\n",
       "      <td>11.092725</td>\n",
       "      <td>9.100386</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>-0.435125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-09-30</th>\n",
       "      <td>-0.034415</td>\n",
       "      <td>-0.028264</td>\n",
       "      <td>0.066512</td>\n",
       "      <td>-3.261722</td>\n",
       "      <td>-3.293365</td>\n",
       "      <td>-2.568575</td>\n",
       "      <td>-0.693147</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.551565</td>\n",
       "      <td>0.025672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>9.271728</td>\n",
       "      <td>11.091665</td>\n",
       "      <td>9.107828</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>-0.027815</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>-0.441626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956-12-31</th>\n",
       "      <td>0.033241</td>\n",
       "      <td>-0.034415</td>\n",
       "      <td>-0.028264</td>\n",
       "      <td>-3.204645</td>\n",
       "      <td>-3.239744</td>\n",
       "      <td>-2.573142</td>\n",
       "      <td>-0.631503</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.571910</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>9.269304</td>\n",
       "      <td>11.086198</td>\n",
       "      <td>9.106428</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>-0.441736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957-03-31</th>\n",
       "      <td>-0.050750</td>\n",
       "      <td>0.033241</td>\n",
       "      <td>-0.034415</td>\n",
       "      <td>-3.289216</td>\n",
       "      <td>-3.260525</td>\n",
       "      <td>-2.616389</td>\n",
       "      <td>-0.672827</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.544177</td>\n",
       "      <td>0.026149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>9.277993</td>\n",
       "      <td>11.096678</td>\n",
       "      <td>9.118405</td>\n",
       "      <td>-0.002524</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>-0.041856</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>-0.444925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 EQP     y_lag    y_2lag        DP        DY        EP  \\\n",
       "time                                                                     \n",
       "1956-03-31  0.066512  0.047768  0.063101 -3.322576 -3.281965 -2.530799   \n",
       "1956-06-30 -0.028264  0.066512  0.047768 -3.333030 -3.269151 -2.575525   \n",
       "1956-09-30 -0.034415 -0.028264  0.066512 -3.261722 -3.293365 -2.568575   \n",
       "1956-12-31  0.033241 -0.034415 -0.028264 -3.204645 -3.239744 -2.573142   \n",
       "1957-03-31 -0.050750  0.033241 -0.034415 -3.289216 -3.260525 -2.616389   \n",
       "\n",
       "                  DE      svar       b/m      ntis  ...      infl         c  \\\n",
       "time                                                ...                       \n",
       "1956-03-31 -0.791778  0.005084  0.509828  0.025245  ... -0.003717  9.274968   \n",
       "1956-06-30 -0.757505  0.003289  0.531077  0.026695  ...  0.000000  9.272498   \n",
       "1956-09-30 -0.693147  0.003688  0.551565  0.025672  ...  0.014925  9.271728   \n",
       "1956-12-31 -0.631503  0.002519  0.571910  0.029362  ...  0.007353  9.269304   \n",
       "1957-03-31 -0.672827  0.004394  0.544177  0.026149  ...  0.007299  9.277993   \n",
       "\n",
       "                    w         y       cay     AAA     BAA        rr     rfree  \\\n",
       "time                                                                            \n",
       "1956-03-31  11.074455  9.093439  0.019292  0.0315  0.0362  0.075561  0.006350   \n",
       "1956-06-30  11.092725  9.100386  0.007275  0.0310  0.0360 -0.022400  0.005625   \n",
       "1956-09-30  11.091665  9.107828  0.000775  0.0326  0.0376 -0.027815  0.006225   \n",
       "1956-12-31  11.086198  9.106428  0.000663  0.0356  0.0407  0.041139  0.007100   \n",
       "1957-03-31  11.096678  9.118405 -0.002524  0.0375  0.0437 -0.041856  0.008025   \n",
       "\n",
       "             new_cay  \n",
       "time                  \n",
       "1956-03-31 -0.423108  \n",
       "1956-06-30 -0.435125  \n",
       "1956-09-30 -0.441626  \n",
       "1956-12-31 -0.441736  \n",
       "1957-03-31 -0.444925  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['new_cay'] = df['c'] - 0.218*df['w'] - 0.801*df['y']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0abe4c",
   "metadata": {},
   "source": [
    "## Plots of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.plot(df['DP'], label='DP')\n",
    "plt.plot(df['DY'], label='DY')\n",
    "        \n",
    "# plt.title('co1', fontsize=20)\n",
    "plt.legend(fontsize=16)\n",
    "plt.savefig('co1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.plot(df['tbl'], label = 'tbl')\n",
    "plt.plot(df['lty'], label = 'lty')\n",
    "        \n",
    "# plt.title('co2', fontsize=20)\n",
    "plt.legend(fontsize=16)\n",
    "plt.savefig('co2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cddc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.plot(df['DP'], label = 'dp')\n",
    "plt.plot(df['EP'], label = 'ep')\n",
    "        \n",
    "# plt.title('co3', fontsize=20)\n",
    "plt.legend(fontsize=16)\n",
    "plt.savefig('co3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2049179",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.plot(df['BAA'], label = 'BAA')\n",
    "plt.plot(df['AAA'], label = 'AAA')\n",
    "        \n",
    "# plt.title('co4', fontsize=20)\n",
    "plt.legend(fontsize=16)\n",
    "plt.savefig('co4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.plot(df['c'], label = 'log of consumption')\n",
    "plt.plot(df['w'], label = 'log of wealth')\n",
    "plt.plot(df['y'], label = 'log of income')\n",
    "        \n",
    "# plt.title('cay', fontsize=20)\n",
    "plt.legend(fontsize=16)\n",
    "plt.savefig('cay.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "plt.plot(df['new_cay'], label = '\"cay\" variable')\n",
    "        \n",
    "# plt.title('cay', fontsize=20)\n",
    "plt.legend(fontsize=16)\n",
    "plt.savefig('new_cay.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753010b8",
   "metadata": {},
   "source": [
    "## Full sample linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec99374",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(df[['y_lag', 'new_cay']], df['EQP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c713032",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c8297",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4eb4e8",
   "metadata": {},
   "source": [
    "## Regression with dy-dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e402276",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpdy = df['DY']-df['DP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25523d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(dpdy.values.reshape(-1,1), df['EQP'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4132bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea060b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xtEhwm9Acx3G",
   "metadata": {
    "id": "xtEhwm9Acx3G"
   },
   "source": [
    "# Construct single-index and nonlinear models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24219b86",
   "metadata": {},
   "source": [
    "### dimension function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UnWCgiROcx3I",
   "metadata": {
    "id": "UnWCgiROcx3I"
   },
   "outputs": [],
   "source": [
    "extra_params = {'sin_func':1,\n",
    "               'cos_func':1,\n",
    "               'scaled_sin_func':2,\n",
    "               'scaled_cos_func':2,\n",
    "               'exp_func':2,\n",
    "               'exp_shift_func':2,\n",
    "                'poly_func':3,\n",
    "                'linear_func':2\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc946dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "co1 = df[['DP', 'DY']]\n",
    "co2 = df[['tbl', 'lty']]\n",
    "co3 = df[['DP', 'EP']]\n",
    "co4 = df[['BAA', 'AAA']]\n",
    "y = df[['EQP']].squeeze()\n",
    "\n",
    "station_ar1 = df[['y_lag', 'new_cay']]\n",
    "\n",
    "cointe_ar1 = [co1, co2, co3, co4]\n",
    "names_ar1 = ['co1', 'co2', 'co3', 'co4']\n",
    "\n",
    "for i in range(len(cointe_ar1)):\n",
    "    cointe_ar1[i].name = names_ar1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff9db1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = co1.join(station_ar1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4bf1c7",
   "metadata": {},
   "source": [
    "## Nonlienar Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kuQiY1Qncx3J",
   "metadata": {
    "id": "kuQiY1Qncx3J"
   },
   "outputs": [],
   "source": [
    "# def sin_func(x): \n",
    "#     station = x \n",
    "#     def objective_func(params):\n",
    "#         d1 = param_num['theta']\n",
    "#         d2 = param_num['beta']\n",
    "        \n",
    "#         theta = params[0:d1]\n",
    "#         beta = params[d1:d1+d2]\n",
    "#         gammas = range(0,param_num['gamma'])\n",
    "        \n",
    "#         u = single_index(x.iloc[:,:d1])(theta)\n",
    "        \n",
    "#         func = np.sin(u + params[d1 + d2 + gammas[0]]) + np.dot(x.iloc[:,d1:d1+d2], beta)\n",
    "#         return func\n",
    "#     return objective_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ed8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models.param_num = {'theta':2,\n",
    "               'beta':2,\n",
    "               'gamma':1\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6c24030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.90222832, -0.87716602,  0.94101479,  0.48557383,  0.32175819])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = CLS_Estimator(obj_func = Models.sin_func, x0 = [0.001]*5, options={'maxiter':50000})\n",
    "cls.fit(X_,y)\n",
    "cls.params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EH7sqihUcx3L",
   "metadata": {
    "id": "EH7sqihUcx3L"
   },
   "outputs": [],
   "source": [
    "def cos_func(x):\n",
    "    def objective_func(params, \n",
    "                       d1 = param_num['theta'], \n",
    "                       d2 = param_num['beta'], \n",
    "                       extra = range(0,param_num['gamma'])):\n",
    "        func = np.cos(single_index(x.iloc[:,:d1])(params[0:d1])+params[d1+d2+extra[0]])+np.dot(\n",
    "            x.iloc[:,d1:d1+d2], params[d1:d1+d2])\n",
    "        return func\n",
    "    return objective_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SfHN6ShHcx3L",
   "metadata": {
    "id": "SfHN6ShHcx3L"
   },
   "outputs": [],
   "source": [
    "# def scaled_sin_func(x):\n",
    "#     def objective_func(params, \n",
    "#                        d1 = param_num['theta'], \n",
    "#                        d2 = param_num['beta'], \n",
    "#                        extra = range(0,param_num['gamma'])):\n",
    "#         func = np.sin(params[d1+d2+extra[1]]*single_index(x.iloc[:,:d1])(\n",
    "#             params[0:d1])+params[d1+d2+extra[0]])+np.dot(x.iloc[:,d1:d1+d2], params[d1:d1+d2])\n",
    "#         return func\n",
    "#     return objective_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SulEuYZTcx3M",
   "metadata": {
    "id": "SulEuYZTcx3M"
   },
   "outputs": [],
   "source": [
    "# def scaled_cos_func(x):\n",
    "#     def objective_func(params, \n",
    "#                        d1 = param_num['theta'], \n",
    "#                        d2 = param_num['beta'], \n",
    "#                        extra = range(0,param_num['gamma'])):\n",
    "#         func = np.cos(params[d1+d2+extra[1]]*single_index(x.iloc[:,:d1])(\n",
    "#             params[0:d1])+params[d1+d2+extra[0]])+np.dot(x.iloc[:,d1:d1+d2], params[d1:d1+d2])\n",
    "#         return func\n",
    "#     return objective_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xv0gTsLAcx3M",
   "metadata": {
    "id": "Xv0gTsLAcx3M"
   },
   "outputs": [],
   "source": [
    "# def exp_shift_func(x):\n",
    "#     def objective_func(params, \n",
    "#                        d1 = param_num['theta'], \n",
    "#                        d2 = param_num['beta'], \n",
    "#                        extra = range(0,param_num['gamma'])):\n",
    "#         func = 1 - np.exp(params[d1+d2+extra[1]]*((single_index(x.iloc[:,:d1])(\n",
    "#             params[0:d1]))-params[d1+d2+extra[0]])**2)+np.dot(x.iloc[:,d1:d1+d2], params[d1:d1+d2])\n",
    "#         return func\n",
    "#     return objective_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SAmhpEOecx3Q",
   "metadata": {
    "id": "SAmhpEOecx3Q"
   },
   "outputs": [],
   "source": [
    "# def exp_func(x):\n",
    "#     def objective_func(params, \n",
    "#                        d1 = param_num['theta'], \n",
    "#                        d2 = param_num['beta'], \n",
    "#                        extra = range(0,param_num['gamma'])):\n",
    "#         func = params[d1+d2+extra[0]]*np.exp(-params[d1+d2+extra[1]]*(single_index(x.iloc[:,:d1])(params[0:d1]))**2\n",
    "#                                 )+np.dot(x.iloc[:,d1:d1+d2], params[d1:d1+d2])\n",
    "#         return func\n",
    "#     return objective_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zUcVWML-cx3R",
   "metadata": {
    "id": "zUcVWML-cx3R"
   },
   "outputs": [],
   "source": [
    "# def poly_func(x):\n",
    "#     def objective_func(params, \n",
    "#                        d1 = param_num['theta'], \n",
    "#                        d2 = param_num['beta'], \n",
    "#                        extra = range(0,param_num['gamma'])):\n",
    "#         func = params[d1+d2+extra[0]]+params[d1+d2+extra[1]]*(single_index(x.iloc[:,:d1])(\n",
    "#             params[0:d1]))+params[d1+d2+extra[2]]*((single_index(x.iloc[:,:d1])(\n",
    "#             params[0:d1]))**2)+np.dot(x.iloc[:,d1:d1+d2], params[d1:d1+d2])\n",
    "# #                (single_index(x.iloc[:,:d1])(params[0:d1])\n",
    "#         return func\n",
    "#     return objective_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5QmBEG1icx3S",
   "metadata": {
    "id": "5QmBEG1icx3S"
   },
   "outputs": [],
   "source": [
    "# def linear_func(x):\n",
    "#     def objective_func(params, \n",
    "#                        d1 = param_num['theta'], \n",
    "#                        d2 = param_num['beta'], \n",
    "#                        extra = range(0,param_num['gamma'])):\n",
    "#         func = params[d1+d2+extra[0]]+params[d1+d2+extra[1]]*(single_index(x.iloc[:,:d1])(\n",
    "#             params[0:d1]))+np.dot(x.iloc[:,d1:d1+d2], params[d1:d1+d2])\n",
    "# #         func = params[d1+d2+extra[0]]+params[d1+d2+extra[1]]*(single_index(x.iloc[:,:d1])(\n",
    "# #             params[0:d1]))\n",
    "# #                (single_index(x.iloc[:,:d1])(params[0:d1])\n",
    "#         return func\n",
    "#     return objective_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84qx1HrPcx3U",
   "metadata": {
    "id": "84qx1HrPcx3U"
   },
   "source": [
    "### Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VZ-Ebf8Mcx3U",
   "metadata": {
    "id": "VZ-Ebf8Mcx3U"
   },
   "outputs": [],
   "source": [
    "def constraint_func(x):\n",
    "    def constraint(params):\n",
    "        con = 0\n",
    "        for j in np.arange(0, x.iloc[:,:d1].shape[1]):\n",
    "            con += params[j]**2\n",
    "            cons = con - 1\n",
    "        return cons\n",
    "    return {'type':'eq', 'fun': constraint}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hwCxXqZRcx39",
   "metadata": {
    "id": "hwCxXqZRcx39"
   },
   "source": [
    "## Empirical Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RUf41-q6cx3-",
   "metadata": {
    "id": "RUf41-q6cx3-"
   },
   "source": [
    "### Cointegrated predictors\n",
    "- dividend-price ratio and dividend yield\n",
    "- T-bill rate and long-term yield\n",
    "- dividend-price ratio and earningprice ratio\n",
    "- baa- and aaa-rated corporate bond yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lNqzmBJScx3-",
   "metadata": {
    "id": "lNqzmBJScx3-"
   },
   "outputs": [],
   "source": [
    "co1 = df[['DP', 'DY']]\n",
    "co2 = df[['tbl', 'lty']]\n",
    "co3 = df[['DP', 'EP']]\n",
    "co4 = df[['BAA', 'AAA']]\n",
    "y = df[['EQP']].squeeze()\n",
    "\n",
    "station_ar1 = df[['y_lag', 'new_cay']]\n",
    "\n",
    "cointe_ar1 = [co1, co2, co3, co4]\n",
    "names_ar1 = ['co1', 'co2', 'co3', 'co4']\n",
    "\n",
    "for i in range(len(cointe_ar1)):\n",
    "    cointe_ar1[i].name = names_ar1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uA6WiESBcx3_",
   "metadata": {
    "id": "uA6WiESBcx3_"
   },
   "outputs": [],
   "source": [
    "# co1_ar2 = df_AR2[['DP', 'DY']]\n",
    "# co2_ar2 = df_AR2[['tbl', 'lty']]\n",
    "# co3_ar2 = df_AR2[['DP', 'EP']]\n",
    "# co4_ar2 = df_AR2[['BAA', 'AAA']]\n",
    "# y_lag2 = df_AR2[['EQP']].squeeze()\n",
    "\n",
    "# station_ar2 = df_AR2[['y_lag', 'new_cay']]\n",
    "\n",
    "# X_train_AR2 = df_AR2.loc[:\"1988-01-01\"]\n",
    "# y_train_AR2 = y_lag2.loc[:\"1988-01-01\"]\n",
    "\n",
    "# X_test_AR2 = df_AR2.loc[\"1988-01-01\":\"2018-12-01\"]\n",
    "# y_test_AR2 = y_lag2.loc[\"1988-01-01\":\"2018-12-01\"]\n",
    "\n",
    "# station_ar2_train = df_AR2.loc[:\"1988-01-01\"][['y_lag', 'new_cay']]\n",
    "\n",
    "# cointe_ar2 = [co1_ar2, co2_ar2, co3_ar2, co4_ar2]\n",
    "# names_ar2 = ['co1', 'co2', 'co3', 'co4']\n",
    "\n",
    "# for i in range(len(cointe_ar1)):\n",
    "#     cointe_ar2[i].name = names_ar2[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QG4LIQmtcx3_",
   "metadata": {
    "id": "QG4LIQmtcx3_"
   },
   "source": [
    "### Stationary variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnIigwHXcx3_",
   "metadata": {
    "id": "qnIigwHXcx3_"
   },
   "source": [
    "### Fit model and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q-yFiuUDcx4A",
   "metadata": {
    "id": "q-yFiuUDcx4A"
   },
   "outputs": [],
   "source": [
    "fun_list = [sin_func,\n",
    "            cos_func,\n",
    "            scaled_sin_func,\n",
    "            scaled_cos_func,\n",
    "            exp_func,\n",
    "            exp_shift_func,\n",
    "            poly_func,\n",
    "            linear_func\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hvsSzKmtcx4A",
   "metadata": {
    "id": "hvsSzKmtcx4A"
   },
   "outputs": [],
   "source": [
    "# Set up hierachical index\n",
    "fun_names = [i.__name__ for i in fun_list]\n",
    "cointe_names = [i.name for i in cointe_ar1]\n",
    "iterables = [fun_names, cointe_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cAB6em6ecx4B",
   "metadata": {
    "id": "cAB6em6ecx4B"
   },
   "outputs": [],
   "source": [
    "#Set up directory\n",
    "parent = os.getcwd()\n",
    "folder = 'results'\n",
    "path = os.path.join(parent, folder)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zckw32edcx4C",
   "metadata": {
    "id": "zckw32edcx4C",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for i, j in itertools.product(fun_list, cointe_ar1):\n",
    "    ################################# Set up dimensions ######################################\n",
    "    d1, d2, extra= dimensions(j,station_ar1, i.__name__)\n",
    "    initial_len = d1+d2+extra[-1]+1\n",
    "    \n",
    "    # Set up dataframes\n",
    "    iterables = [[i.__name__], [j.name]]\n",
    "    sec_columns = ['param_'+str(i) for i in range(1,initial_len+1)]\n",
    "    multi_index = pd.MultiIndex.from_product(iterables, names=[\"function\", \"variables\"])\n",
    "    multi_columns = pd.MultiIndex.from_product([['NLS', 'CLS'], sec_columns],\n",
    "                                               names=['Estimator', 'Parameters'])\n",
    "    result = pd.DataFrame(index = multi_index, columns = multi_columns)\n",
    "    ###################################### Set up X ##########################################\n",
    "    X_ = j.join(station_ar1)\n",
    "    # Fit models\n",
    "    nls = CLS_Estimator(obj_func = i, x0 = [0.001]*initial_len, options={'maxiter':50000})\n",
    "    cls = CLS_Estimator(obj_func = i, x0 = [0.001]*initial_len, constraints = constraint_func(X_), options={'maxiter':50000})\n",
    "    nls.params_ = nls.fit(X_,y).params_\n",
    "    cls.params_ = cls.fit(X_,y).params_\n",
    "    # Save results to dataframe\n",
    "    result.loc[i.__name__,j.name].loc['NLS'] = nls.params_ \n",
    "    result.loc[i.__name__,j.name].loc['CLS'] = cls.params_ \n",
    "    # Put into one table\n",
    "    results = results.append(result, ignore_index = False, sort = False)\n",
    "    \n",
    "# Export to Excel\n",
    "results.to_excel('results/full_sample_new_cay.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZC5tf-NOcx4D",
   "metadata": {
    "id": "ZC5tf-NOcx4D"
   },
   "source": [
    "## Use initial values from Linear regression (using Taylor expansion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UqINcCw-cx4E",
   "metadata": {
    "id": "UqINcCw-cx4E"
   },
   "outputs": [],
   "source": [
    "orders = {'sin_func':1,\n",
    "          'cos_func':2,\n",
    "          'scaled_sin_func':1,\n",
    "          'scaled_cos_func':2,\n",
    "          'exp_func':5,\n",
    "          'exp_shift_func':2,\n",
    "          'poly_func':2,\n",
    "          'linear_func':1\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zH2DcF0bcx4E",
   "metadata": {
    "id": "zH2DcF0bcx4E"
   },
   "outputs": [],
   "source": [
    "def Taylor_init(variables, station, y, function):\n",
    "    \n",
    "    d1, d2, extra = dimensions(variables, station, function.__name__)\n",
    "    \n",
    "    # find the initials for theta\n",
    "    LR = LinearRegression()\n",
    "    LR_theta = LR.fit(variables.iloc[:,1:], variables.iloc[:,:1])\n",
    "    alpha = np.append(1, -LR_theta.coef_)\n",
    "    theta = np.array(-alpha/np.linalg.norm(alpha))\n",
    "#     print(len(theta))\n",
    "    \n",
    "    # calculate single-index\n",
    "    u = single_index(variables)(theta)\n",
    "    \n",
    "    # find the initials for beta\n",
    "    Xs = station.copy()\n",
    "#     print(Xs.shape[1])\n",
    "    Xs['u'], Xs['u2'], Xs['u3'], Xs['u4'], Xs['u6'] = u, u**2, u**3, u**4, u**6\n",
    "    t_order = orders.get(function.__name__)\n",
    "    \n",
    "    if function == exp_func:\n",
    "        X_reg = Xs.iloc[:, 0:d2+t_order].drop(['u', 'u3'], axis = 1)\n",
    "    else:\n",
    "        X_reg = Xs.iloc[:, 0:d2+t_order]\n",
    "#     print(X_reg)\n",
    "    LR_taylor = LR.fit(X_reg, y)\n",
    "    theta_beta = np.append(theta,LR_taylor.coef_[:d2])\n",
    "#     print(len(theta_gamma))\n",
    "    \n",
    "    \n",
    "    # initials for gammas\n",
    "    initials = []\n",
    "    if function == sin_func:\n",
    "        initials = np.append(theta_beta, LR_taylor.intercept_)\n",
    "    elif function == scaled_sin_func:\n",
    "        initials = np.append(theta_beta, ([LR_taylor.coef_[0]], [LR_taylor.intercept_]))\n",
    "    elif function == linear_func:\n",
    "        initials = np.append(theta_beta, ([LR_taylor.intercept_], [LR_taylor.coef_[0]]))\n",
    "    elif function == poly_func:\n",
    "        ini_poly_ = np.append(theta_beta,LR_taylor.coef_[d2:])\n",
    "        initials = np.insert(ini_poly_, 4, LR_taylor.intercept_)\n",
    "    elif function == cos_func:\n",
    "        initials = np.append(theta_beta, [-LR_taylor.coef_[-1]/2])\n",
    "#         print(-LR_taylor.coef_[-1]/2, -LR_taylor.coef_[d2])\n",
    "    elif function == scaled_cos_func:\n",
    "        initials = np.append(theta_beta,(\n",
    "            [-LR_taylor.coef_[d2]/2*np.sqrt(np.abs(1-LR_taylor.intercept_)),np.sqrt(np.abs(1-LR_taylor.intercept_))]))\n",
    "#         print(1-LR_taylor.intercept_)\n",
    "    elif function == exp_shift_func:\n",
    "        initials = np.append(theta_beta, \n",
    "                             [np.sqrt(np.abs(LR_taylor.coef_[-1])),LR_taylor.coef_[-2]/np.sqrt(np.abs(LR_taylor.coef_[-1]))])\n",
    "#         print(LR_taylor.coef_, LR_taylor.coef_[-2])\n",
    "    elif function == exp_func:\n",
    "        initials =np.append(theta_beta, [LR_taylor.intercept_, -LR_taylor.coef_[-3]])\n",
    "#         initials =np.append(theta_beta, [LR_taylor.intercept_, np.sqrt(np.abs(2*LR_taylor.coef_[-2]/(LR_taylor.intercept_)))])\n",
    "\n",
    "    return initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054aa095",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions(co3, station_ar1, cos_func.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d242c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taylor_init(co3, station_ar1, y, scaled_cos_func)\n",
    "Taylor_init(co2.loc[:\"1988-01-01\"], station_ar1.loc[:\"1988-01-01\"], y.loc[:\"1988-01-01\"], exp_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8uG4qK0Lcx4G",
   "metadata": {
    "id": "8uG4qK0Lcx4G"
   },
   "source": [
    "# Fit model and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TE1AZ9W2cx4G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13559,
     "status": "ok",
     "timestamp": 1627946314791,
     "user": {
      "displayName": "Ying Zhou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHV9f7CxBRGPIo2NDc6TBV5JOSCfiAUOEd5qEa=s64",
      "userId": "01839765169556069563"
     },
     "user_tz": -600
    },
    "id": "TE1AZ9W2cx4G",
    "outputId": "496e1682-9814-41e5-e8f4-9731bc58b3c5"
   },
   "outputs": [],
   "source": [
    "results_Taylor = pd.DataFrame()\n",
    "for i, j in itertools.product(fun_list, cointe_ar1):\n",
    "    # Set up dimensions\n",
    "    d1, d2, extra= dimensions(j,station_ar1, i.__name__)\n",
    "    initial_len = d1+d2+extra[-1]+1\n",
    "    # Set up dataframes\n",
    "    iterables = [[i.__name__], [j.name]]\n",
    "    sec_columns = ['param_'+str(i) for i in range(1,initial_len+1)]\n",
    "    multi_index = pd.MultiIndex.from_product(iterables, names=[\"function\", \"variables\"])\n",
    "    multi_columns = pd.MultiIndex.from_product([['NLS', 'CLS'], sec_columns],\n",
    "                                               names=['Estimator', 'Parameters'])\n",
    "    result = pd.DataFrame(index = multi_index, columns = multi_columns)\n",
    "    # Prepare X\n",
    "    X_ = j.join(station_ar1)\n",
    "    # Fit models\n",
    "    nls = CLS_Estimator(obj_func = i, x0 = Taylor_init(j, station_ar1, y, i), options={'maxiter':1000000})\n",
    "    cls = CLS_Estimator(obj_func = i, x0 = Taylor_init(j, station_ar1, y, i), constraints = constraint_func(X_), \n",
    "                        options={'maxiter':1000000})\n",
    "    nls.params_ = nls.fit(X_,y).params_\n",
    "    cls.params_ = cls.fit(X_,y).params_\n",
    "    print(i.__name__, j.name)\n",
    "    # Save results to dataframe\n",
    "    result.loc[i.__name__,j.name].loc['NLS'] = nls.params_ \n",
    "    result.loc[i.__name__,j.name].loc['CLS'] = cls.params_ \n",
    "    # Put into one table\n",
    "    results_Taylor = results_Taylor.append(result, ignore_index = False, sort = False)\n",
    "    \n",
    "# Export to Excel\n",
    "results_Taylor.to_excel('results/full_taylor_new_cay.xlsx')\n",
    "results_Taylor.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ac833IaZLnmK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1627946385856,
     "user": {
      "displayName": "Ying Zhou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHV9f7CxBRGPIo2NDc6TBV5JOSCfiAUOEd5qEa=s64",
      "userId": "01839765169556069563"
     },
     "user_tz": -600
    },
    "id": "Ac833IaZLnmK",
    "outputId": "ef7b5d40-02ff-4481-bfb9-faedb4cd4e67"
   },
   "outputs": [],
   "source": [
    "results_Taylor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fL_NT4jIcx4H",
   "metadata": {
    "id": "fL_NT4jIcx4H"
   },
   "source": [
    "### GridSearch and CrossValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MzwsywXzcx4I",
   "metadata": {
    "id": "MzwsywXzcx4I"
   },
   "source": [
    "### Train_test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mr7oBChzcx4I",
   "metadata": {
    "id": "mr7oBChzcx4I"
   },
   "outputs": [],
   "source": [
    "# val_length = 1\n",
    "test_length = 31\n",
    "step = 1\n",
    "### quarterly data:4\n",
    "freq = 4\n",
    "# cv_outer = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=int((12/step) * test_length), test_size=step)\n",
    "# cv_inner = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=int((12/step) * val_length), test_size=step)\n",
    "cv_outer = TimeSeriesSplit(max_train_size=None, n_splits=test_length*freq, test_size=step, gap=0)\n",
    "# cv_inner = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=4, test_size=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b3a6d",
   "metadata": {},
   "source": [
    "### set up dataframes for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7QncEs5ccx4K",
   "metadata": {
    "id": "7QncEs5ccx4K"
   },
   "outputs": [],
   "source": [
    "oos_MSE = pd.DataFrame()\n",
    "\n",
    "rows = df.loc[\"1988-01-01\":\"2018-12-01\"].index\n",
    "sec_columns = ['CLS_MSE', 'SM_MSE', 'NLS_MSE', 'AR1_MSE', 'AR2_MSE', 'AR_cay_MSE']\n",
    "multi_columns = pd.MultiIndex.from_product([['co1', 'co2', 'co3', 'co4'], sec_columns],names=['Variable', 'Model'])\n",
    "        \n",
    "oos_MSE = pd.DataFrame(index = multi_columns, columns = rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acef75",
   "metadata": {},
   "source": [
    "#### The block below is used to test the OOS results only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60cf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func = linear_func\n",
    "\n",
    "x0 = Taylor_init(co1_ar2.loc[:\"1988-01-01\"], station_n.loc[:\"1988-01-01\"], y_train_AR2.loc[:\"1988-01-01\"], func)\n",
    "\n",
    "X_ = co1_ar2.join(station_n) \n",
    "d1, d2, extra= dimensions(co1_ar2,station_n, func.__name__)\n",
    "# # cls = CLS_Estimator(obj_func = sin_func, x0 = x0, constraints = constraint_func(X_))\n",
    "# cls = CLS_Estimator(obj_func = sin_func, x0 = [0.001]*(d1+d2+extra[-1]+1), constraints = constraint_func(X_))\n",
    "# cv_result = cross_validate(cls, X_, y_lag2, cv=cv_outer, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "# mse_s0 = cv_result['test_score']\n",
    "# mse_s0[:5]\n",
    "# mse_st = cv_result['test_score']\n",
    "# mse_st[:5]\n",
    "\n",
    "a = []\n",
    "for train_index, test_index in cv_outer.split(X_):\n",
    "    X_train, X_test = X_.iloc[train_index, :], X_.iloc[test_index, :]\n",
    "    y_train, y_test = y_lag2.iloc[train_index], y_lag2.iloc[test_index]\n",
    "    cls = CLS_Estimator(obj_func = func, x0 = x0, constraints = constraint_func(X_))\n",
    "#     cls = CLS_Estimator(obj_func = sin_func, x0 = [0.001]*(d1+d2+extra[-1]+1), constraints = constraint_func(X_))\n",
    "    cls.fit(X_train, y_train)\n",
    "    a.append(cls.params_)\n",
    "a = pd.DataFrame(a)\n",
    "a.to_excel('coefs_g8_newcay.xlsx', sheet_name = 'both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for train_index, test_index in cv_outer.split(X_):\n",
    "    X_train, X_test = X_.iloc[train_index, :], X_.iloc[test_index, :]\n",
    "    y_train, y_test = y_lag2.iloc[train_index], y_lag2.iloc[test_index]\n",
    "    x = X_train.to_numpy()\n",
    "    y_m = y_train.to_numpy()\n",
    "    \n",
    "#     beta = np.matmul(np.matmul(np.linalg.inv(np.matmul(x.T, x)), x.T), y_m)\n",
    "#     alp = np.mean(y_m) - np.matmul(beta, np.mean(x, axis = 0))\n",
    "    lr.fit(X_train, y_train)\n",
    "    beta = lr.coef_\n",
    "    alp = lr.intercept_\n",
    "    coef = np.append(alp, beta)\n",
    "    a.append(coef)\n",
    "a = pd.DataFrame(a)\n",
    "a.to_excel('linear_func.xlsx', sheet_name = 'both')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac35a7",
   "metadata": {},
   "source": [
    "## Generate OOS MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65988163",
   "metadata": {},
   "source": [
    "### project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_list = [\n",
    "            sin_func,\n",
    "            cos_func,\n",
    "            exp_func,\n",
    "            exp_shift_func,\n",
    "            poly_func\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68638ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = df['rr']\n",
    "rfree = df['rfree']\n",
    "station_n = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ecdd5",
   "metadata": {},
   "source": [
    "### CER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c1ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "P2_pred = {}\n",
    "        \n",
    "for i in fun_list:\n",
    "    print(i.__name__)\n",
    "    for j in cointe_ar1:    \n",
    "        # Prepare X\n",
    "        X_ = j.join(station_n)\n",
    "        pred_list = []\n",
    "        ##################################### no need to loop! ##############################################################\n",
    "        for train_index, test_index in cv_outer.split(X_):\n",
    "#             print(train_index)\n",
    "            X_train, X_test = X_.iloc[train_index, :], X_.iloc[test_index, :]\n",
    "            rr_train, rr_test = rr.iloc[train_index], rr.iloc[test_index]\n",
    "            # benchmark model: sm\n",
    "            sm_pred, sm_mse = bench.sample_mean(rr, \"1988-01-01\", cv_outer = cv_outer)\n",
    "            P2_pred['SM'] = sm_pred\n",
    "            # benchmark model: Nonlinear\n",
    "            station_n = pd.DataFrame()\n",
    "            d1, d2, extra= dimensions(j,station_n, i.__name__)\n",
    "        \n",
    "            nlr = CLS_Estimator(obj_func = i, x0 = [0.001]*(d1+d2+extra[-1]+1), constraints = constraint_func(j))\n",
    "            nlr.fit(X_train, rr_train)\n",
    "            pred_list.append(nlr.predict(X_test)[0])\n",
    "            P2_pred[(i.__name__, j.name)] = pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eccb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "P2_pred = pd.DataFrame.from_dict(P2_pred)\n",
    "P2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aec47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "P2_pred = pd.read_excel('results/P2_signif/p2_pred.xlsx', header=[0,1], index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2 = []\n",
    "for train_index, test_index in cv_outer.split(X_):\n",
    "    X_train, X_test = X_.iloc[train_index, :], X_.iloc[test_index, :]\n",
    "    rr_train, rr_test = rr.iloc[train_index], rr.iloc[test_index]\n",
    "    sigma2.append((np.std(rr_train[-20:]))**2)\n",
    "\n",
    "Rp_dict = {}\n",
    "CER = {}\n",
    "for j in P2_pred.columns:\n",
    "    w = []\n",
    "    w_raw = (1/5)*(np.asarray(P2_pred[j])/np.asarray(sigma2))\n",
    "    for k,i in enumerate(w_raw):\n",
    "        if i<0:\n",
    "            w.append(0)\n",
    "        elif i>1.5:\n",
    "            w.append(1.5)\n",
    "        else:\n",
    "            w.append(i)\n",
    "    Rp = w*rr['1988-03-01':]+rfree['1988-03-01':]\n",
    "    Rp_dict[j] = Rp\n",
    "    CER_cal = np.mean(Rp) - 0.5*5*(np.std(Rp)**2)\n",
    "    CER[j] = CER_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rp_dict = pd.DataFrame.from_dict(Rp_dict)\n",
    "Rp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rp_dict.to_excel('Rp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CER = pd.DataFrame.from_dict(CER, orient = 'index', columns = ['CER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c2c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "CER['delta_CER'] = CER['CER'] - CER.loc['SM'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2ce321",
   "metadata": {},
   "outputs": [],
   "source": [
    "CER.to_excel('results/CER.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60510771",
   "metadata": {},
   "outputs": [],
   "source": [
    "    w_sm = []\n",
    "    w_raw = (1/5)*(np.asarray(sm_pred)/np.asarray(sigma2))\n",
    "    for k,i in enumerate(w_raw):\n",
    "        if i<0:\n",
    "            w_sm.append(0)\n",
    "        elif i>1.5:\n",
    "            w_sm.append(1.5)\n",
    "        else:\n",
    "            w_sm.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w_sm[:56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rp_sm = w_sm[:56]*rr['1988-03-01':'2001-12-01']+rfree['1988-03-01':'2001-12-01']\n",
    "CER_sm = np.mean(Rp_sm) - 0.5*5*(np.std(Rp_sm)**2)\n",
    "CER_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = w_sm*rr['1988-03-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rp_sm = a['1996-03-01':'2011-12-01']+rfree['1996-03-01':'2011-12-01']\n",
    "CERp = np.mean(Rp_sm) - 0.5*5*(np.std(Rp:'2001-12-01'_sm)**2)\n",
    "CERp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ejG9vnhfcx4M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 986849,
     "status": "ok",
     "timestamp": 1627967992918,
     "user": {
      "displayName": "Ying Zhou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHV9f7CxBRGPIo2NDc6TBV5JOSCfiAUOEd5qEa=s64",
      "userId": "01839765169556069563"
     },
     "user_tz": -600
    },
    "id": "ejG9vnhfcx4M",
    "outputId": "d7aacdc1-814e-4608-99f5-2412f7ac2816",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "P2_MSE = {}\n",
    "        \n",
    "for i in fun_list:\n",
    "    print(i.__name__)\n",
    "    for j in cointe_ar1:    \n",
    "        # Prepare X\n",
    "        X_ = j.join(station_ar1)\n",
    "        \n",
    "        ##################################### no need to loop! ##############################################################\n",
    "        # benchmark model: sm\n",
    "        sm_pred, sm_mse = bench.sample_mean(y, \"1988-01-01\", cv_outer = cv_outer)\n",
    "        P2_MSE['SM'] = sm_mse\n",
    "        # benchmark model: Nonlinear\n",
    "        station_n = pd.DataFrame()\n",
    "        d1, d2, extra= dimensions(j,station_n, i.__name__)\n",
    "        \n",
    "        nlr = CLS_Estimator(obj_func = i, x0 = [0.001]*(d1+d2+extra[-1]+1), constraints = constraint_func(j))\n",
    "        cv_nonlinear = cross_validate(nlr, j, y, cv=cv_outer, scoring = 'neg_mean_squared_error')\n",
    "        P2_MSE[(i.__name__, j.name)] = -cv_nonlinear['test_score']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "P2_MSE = pd.DataFrame.from_dict(P2_MSE)\n",
    "P2_MSE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c7c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_dict = {}\n",
    "for i, j in itertools.product(fun_list, cointe_ar1):\n",
    "    cumu_sum = []\n",
    "    target_sum = []\n",
    "    cumu_R2 = []\n",
    "    for R in range(P2_MSE.shape[0]):\n",
    "        target_sum.append(P2_MSE[(i.__name__,j.name)][-(R+1):].sum())\n",
    "        cumu_sum.append(P2_MSE['SM'][-(R+1):].sum())\n",
    "    cumu_R2 = [1 - x/y for x,y in zip(target_sum, cumu_sum)]\n",
    "    R2_dict[(i.__name__, j.name)] = cumu_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbbab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "P2_R2 = pd.DataFrame.from_dict(R2_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca943b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "P2_R2.to_excel('P2_R2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1916e988",
   "metadata": {},
   "source": [
    "### Starting Values: from taylors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = co1.join(station_ar1)\n",
    "for train_index, test_index in cv_outer.split(X_):\n",
    "    X_train, X_test = X_.iloc[train_index, :], X_.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    print(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = CLS_Estimator(obj_func = i, x0 = x0, constraints = constraint_func(X_), options={'maxiter':1000000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3HtoaaFThtyq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1627967993372,
     "user": {
      "displayName": "Ying Zhou",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHV9f7CxBRGPIo2NDc6TBV5JOSCfiAUOEd5qEa=s64",
      "userId": "01839765169556069563"
     },
     "user_tz": -600
    },
    "id": "3HtoaaFThtyq",
    "outputId": "528214ea-306e-4c65-cdcf-8799e5017ee1"
   },
   "outputs": [],
   "source": [
    "writer_MSE = pd.ExcelWriter('MSE_taylor_newcay.xlsx', engine='xlsxwriter')\n",
    "        \n",
    "for i in fun_list:\n",
    "    print(i.__name__)\n",
    "    for j in cointe_ar1:\n",
    "        # Prepare X\n",
    "        X_ = j.join(station_ar1) \n",
    "#         print(X_)\n",
    "        \n",
    "        # Fit models\n",
    "        x0 = Taylor_init(j.loc[:\"1988-01-01\"], station_ar1.loc[:\"1988-01-01\"], y.loc[:\"1988-01-01\"], i)\n",
    "        # Target model\n",
    "        d1, d2, extra= dimensions(j,station_ar1, i.__name__)\n",
    "        \n",
    "        cls = CLS_Estimator(obj_func = i, x0 = x0, constraints = constraint_func(X_), options={'maxiter':1000000})\n",
    "#         print(cls.predict(X_))\n",
    "        cv_result = cross_validate(cls, X_, y, cv=cv_outer, scoring = 'neg_mean_squared_error')\n",
    "#         print(-cv_result['test_score'])\n",
    "        oos_MSE.loc[j.name].loc['CLS_MSE'] = -cv_result['test_score']\n",
    "        print(j.name, 'finish cls')\n",
    "        ##################################### no need to loop! ##############################################################\n",
    "        # benchmark model: sm\n",
    "        sm_pred, sm_mse = bench.sample_mean(y, \"1988-01-01\", cv_outer = cv_outer)\n",
    "        oos_MSE.loc[j.name].loc['SM_MSE'] = sm_mse\n",
    "        \n",
    "        # benchmark model: Nonlinear\n",
    "        station_n = pd.DataFrame()\n",
    "        d1, d2, extra= dimensions(j,station_n, i.__name__)\n",
    "        x0_n = Taylor_init(j.loc[:\"1988-01-01\"], station_n, y.loc[:\"1988-01-01\"], i)\n",
    "        \n",
    "        nlr = CLS_Estimator(obj_func = i, x0 = x0_n, constraints = constraint_func(j), options={'maxiter':1000000})\n",
    "        cv_nonlinear = cross_validate(nlr, j, y, cv=cv_outer, scoring = 'neg_mean_squared_error')\n",
    "        oos_MSE.loc[j.name].loc['NLS_MSE'] = -cv_nonlinear['test_score']    \n",
    "        print(j.name, 'finish nls')\n",
    "        # benchmark model: AR1\n",
    "        lr = LinearRegression()\n",
    "        \n",
    "        ar1 = df['y_lag']\n",
    "        cv_ar1 = cross_validate(lr, ar1.values.reshape(-1, 1), y, cv=cv_outer, scoring = 'neg_mean_squared_error')\n",
    "        oos_MSE.loc[j.name].loc['AR1_MSE'] = -cv_ar1['test_score']\n",
    "        \n",
    "        # AR2\n",
    "        ar2 = df[['y_lag','y_2lag']]\n",
    "        cv_ar2 = cross_validate(lr, ar2, y, cv=cv_outer, scoring = 'neg_mean_squared_error')\n",
    "        oos_MSE.loc[j.name].loc['AR2_MSE'] = -cv_ar2['test_score']\n",
    "\n",
    "        # benchmark model: AR+cay\n",
    "        ar_cay = df[['y_lag','new_cay']]\n",
    "        cv_cay = cross_validate(lr, ar_cay, y, cv=cv_outer, scoring = 'neg_mean_squared_error')\n",
    "        oos_MSE.loc[j.name].loc['AR_cay_MSE'] = -cv_cay['test_score']\n",
    "\n",
    "        ####################################################################################################\n",
    "        oos_MSE.T.to_excel(writer_MSE, sheet_name=i.__name__)\n",
    "        \n",
    "writer_MSE.save()\n",
    "writer_MSE.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aVqCSLfHcx4X",
   "metadata": {
    "id": "aVqCSLfHcx4X"
   },
   "source": [
    "## $R^2$ Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EvGLtYY3cx4X",
   "metadata": {
    "id": "EvGLtYY3cx4X"
   },
   "source": [
    "### oos $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CV5AWitRcx4X",
   "metadata": {
    "id": "CV5AWitRcx4X"
   },
   "outputs": [],
   "source": [
    "base = ['SM',\n",
    "       'NLS',\n",
    "       'AR1',\n",
    "       'AR2',\n",
    "       'AR_cay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbdbdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_list = ['co1', 'co2', 'co3', 'co4']\n",
    "co_dict = {'co1': 'dy and dp',\n",
    "          'co2': 'tbl and lty',\n",
    "          'co3': 'dp and ep',\n",
    "          'co4': 'BAA and AAA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oos_MSE = pd.read_excel('MSE_taylor_0831.xlsx', header=[0,1], index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff42c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# oos_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67260b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulate_R2 = pd.DataFrame()\n",
    "\n",
    "rows = oos_MSE.loc[\"1988-01-01\":\"2018-12-01\"].index\n",
    "sec_columns_R2 = ['SM', 'NLS', 'AR1', 'AR2', 'AR_cay']\n",
    "multi_columns_R2 = pd.MultiIndex.from_product([['co1', 'co2', 'co3', 'co4'], sec_columns_R2],\n",
    "                                                  names=['Variable', 'Model'])      \n",
    "cumulate_R2 = pd.DataFrame(index = multi_columns_R2, columns = rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea1708",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulate_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b804acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_R2 = pd.ExcelWriter('R2_taylor_newcay.xlsx', engine='xlsxwriter')\n",
    "\n",
    "for f in fun_list:\n",
    "    oos_MSE = pd.read_excel('MSE_taylor_newcay.xlsx', header=[0,1], index_col=0, sheet_name = f.__name__)\n",
    "    for i, j in itertools.product(base, co_list):\n",
    "#         print(i,j)\n",
    "        cumu_sum = []\n",
    "        target_sum = []\n",
    "        cumu_R2 = []\n",
    "        k = i + '_MSE'\n",
    "        for R in range(len(oos_MSE[j][k])):\n",
    "            target_sum.append(oos_MSE[j]['CLS_MSE'][:(R+1)].sum())\n",
    "            cumu_sum.append(oos_MSE[j][k][:(R+1)].sum())\n",
    "        cumu_R2 = [1 - x/y for x,y in zip(target_sum, cumu_sum)]\n",
    "#         print(len(cumu_R2))\n",
    "        cumulate_R2.loc[j].loc[i] = cumu_R2\n",
    "    cumulate_R2.T.to_excel(writer_R2, sheet_name=f.__name__)\n",
    "writer_R2.save()\n",
    "writer_R2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15868af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = os.getcwd()\n",
    "folder = 'OOS_plots/taylor_newacy'\n",
    "path = os.path.join(parent, folder)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "for k in fun_list:\n",
    "    R2 = pd.read_excel('R2_taylor_newcay.xlsx', header=[0,1], index_col=0, sheet_name = k.__name__)['1989-03-01':]\n",
    "    for i,j in itertools.product(co_list, base):\n",
    "        fig = plt.figure(figsize = (12,8))\n",
    "        plt.plot(R2[i][j])\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.title('1-Step OOS: '+ co_dict[i] + ' (' + 'Model: '+ k.__name__[:-5] + '; BM:' + j + ')', fontsize=20)\n",
    "        plt.ylabel(\"$R^2_{OOS}$\", fontsize=16)\n",
    "        plt.savefig(os.path.join(path, k.__name__[:-5] + '_' + i + '_' + j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74281030",
   "metadata": {},
   "source": [
    "## Regenerate results for project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_R2 = pd.ExcelWriter('results/OOS_R2_project2.xlsx', engine='xlsxwriter')\n",
    "\n",
    "for f in fun_list:\n",
    "    oos_MSE = pd.read_excel('results/OOS_MSE_start0.xlsx', header=[0,1], index_col=0, sheet_name = f)\n",
    "    for i, j in itertools.product(base, co_list):\n",
    "        cumu_sum = []\n",
    "        target_sum = []\n",
    "        cumu_R2 = []\n",
    "        k = i + '_MSE'\n",
    "        for R in range(len(oos_MSE[j][k])):\n",
    "            target_sum.append(oos_MSE[j]['NLS_MSE'][-(R+1):].sum())\n",
    "            cumu_sum.append(oos_MSE[j][k][-(R+1):].sum())\n",
    "        cumu_R2 = [1 - x/y for x,y in zip(target_sum, cumu_sum)]\n",
    "        cumulate_R2.loc[j].loc[i] = cumu_R2\n",
    "    cumulate_R2.T.to_excel(writer_R2, sheet_name=f)\n",
    "writer_R2.save()\n",
    "writer_R2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6baa9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_list = ['sin_func',\n",
    "            'cos_func',\n",
    "            'scaled_sin_func',\n",
    "            'scaled_cos_func',\n",
    "            'exp_shift_func',\n",
    "            'exp_func',\n",
    "            'poly_func']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca54c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = os.getcwd()\n",
    "folder = 'OOS_plots/project2'\n",
    "path = os.path.join(parent, folder)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "for k in fun_list:\n",
    "    R2 = pd.read_excel('results/OOS_R2_project2.xlsx', header=[0,1], index_col=0, sheet_name = k)\n",
    "    for i in co_list:\n",
    "#         print(i)\n",
    "        fig = plt.figure(figsize = (12,8))\n",
    "        plt.plot(R2[i]['SM'])\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        \n",
    "        plt.title('1-Step OOS: '+ i + ' (' + 'Model: '+ k[:-5] + '; BM:' + 'SM' + ', start:0)', fontsize=20)\n",
    "        plt.ylabel(\"$R^2_{OOS}$\", fontsize=16)\n",
    "        plt.savefig(os.path.join(path, k[:-5] + '_' + i + '_' + 'SM' + '_0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9835d",
   "metadata": {},
   "source": [
    "# Plot U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb63d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_excel('results/full_sample.xlsx', header=[0,1], index_col=[0,1])\n",
    "results_taylor = pd.read_excel('results/Taylor_fullsample.xlsx', header=[0,1], index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up directory\n",
    "parent = os.getcwd()\n",
    "folder = 'single_index'\n",
    "path = os.path.join(parent, folder)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "for k in fun_list:\n",
    "    for i,j in enumerate(cointe_ar2):\n",
    "        fig = plt.figure(figsize = (8,6))\n",
    "        plt.plot(single_index(j)(results_taylor['CLS'][['param_1', 'param_2']].loc[k].loc[co_list[i]]))\n",
    "        plt.title('single-index: '+ co_list[i] + ' (' + 'Model: '+ k[:-5] + ')', fontsize=20)\n",
    "        plt.savefig(os.path.join(path, k[:-5] + '_' + co_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2ddb8",
   "metadata": {},
   "source": [
    "# In-sample $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_n = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_R3 = pd.ExcelWriter('insample_R2_newcay.xlsx', engine='xlsxwriter')\n",
    "\n",
    "R2_insample = pd.DataFrame()\n",
    "for i, j in itertools.product(fun_list, cointe_ar1):\n",
    "    # Set up dimensions\n",
    "    d1, d2, extra= dimensions(j,station_ar1, i.__name__)\n",
    "    # Set up dataframes\n",
    "    iterables = [[i.__name__], [j.name]]\n",
    "    sec_columns = ['in_sample R2']\n",
    "    multi_index = pd.MultiIndex.from_product(iterables, names=[\"function\", \"variables\"])\n",
    "    R2_in = pd.DataFrame(index = multi_index, columns = sec_columns)\n",
    "    # Prepare X\n",
    "    X_ = j.join(station_ar1)\n",
    "    d1, d2, extra= dimensions(j,station_n, i.__name__)\n",
    "    initial_len = d1+d2+extra[-1]+1\n",
    "    # Fit models\n",
    "    cls = CLS_Estimator(obj_func = i, x0 = Taylor_init(j, station_ar1, y, i), constraints = constraint_func(X_))\n",
    "    cls.fit(X_, y)\n",
    "    R2_ins = 1 - np.sum((cls.predict(X_) - np.array(y))**2)/np.sum((np.array(y)-np.mean(y))**2)\n",
    "    R2_in.loc[i.__name__,j.name].loc['in_sample R2'] = R2_ins\n",
    "    R2_insample = R2_insample.append(R2_in, ignore_index = False, sort = False)\n",
    "    R2_insample.to_excel(writer_R3)\n",
    "writer_R3.save()\n",
    "writer_R3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0298e14c",
   "metadata": {},
   "source": [
    "# NLS significance of $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1938154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up directory\n",
    "parent = os.getcwd()\n",
    "folder = 'P2_signif'\n",
    "path = os.path.join(os.path.join(parent, 'result'), folder)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111885ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_list = [sin_func,\n",
    "            cos_func,\n",
    "            scaled_sin_func,\n",
    "            scaled_cos_func,\n",
    "            exp_func,\n",
    "            exp_shift_func,\n",
    "            poly_func, \n",
    "            linear_func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for i,j in itertools.product(fun_list, cointe_ar1):\n",
    "#     print(i.__name__, j.name)\n",
    "    pred = np.empty(0)\n",
    "    for train, test in cv_outer.split(j):\n",
    "        station_n = pd.DataFrame()\n",
    "        d1, d2, extra= dimensions(j,station_n, i.__name__)\n",
    "        # CLS without linear part\n",
    "        nlr = CLS_Estimator(obj_func = i, x0 = [0.001]*(d1+d2+extra[-1]+1), constraints = constraint_func(j))\n",
    "        nlr.fit(j.iloc[train,:],y.iloc[train])\n",
    "        pred = np.append(pred, nlr.predict(j.iloc[test,:]))\n",
    "    result_dict[(i.__name__, j.name)] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914cb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_pred = pd.DataFrame.from_dict(result_dict)\n",
    "p2_pred.to_excel(path+'/p2_pred.xlsx', engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37ddd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_pred.index = y[-124:].index\n",
    "p2_pred['EQP'] = y[-124:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred, sm_mse = bench.sample_mean(y, \"1988-01-01\", cv_outer = cv_outer)\n",
    "p2_pred['SM'] = sm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cef944",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_dict = {}\n",
    "for i,j in itertools.product(fun_list, cointe_ar1):\n",
    "    y_hat = p2_pred[i.__name__][j.name]\n",
    "    y_sm = p2_pred['SM']\n",
    "    y_true = p2_pred['EQP']\n",
    "    sig_dict[(i.__name__, j.name)] = (y_true - y_sm)**2 - (y_true - y_hat)**2 + (y_sm - y_hat)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7680cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_df = pd.DataFrame.from_dict(sig_dict)\n",
    "sig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b68179",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_dict = {}\n",
    "# p_dict = {}\n",
    "for i,j in itertools.product(fun_list, cointe_ar1):\n",
    "    t_val = []\n",
    "    p_val = []\n",
    "    for k in range(4,sig_df.shape[0]):\n",
    "        x = np.repeat(1, k).reshape(-1,1)\n",
    "        ind = sig_df.index[k-1]\n",
    "        models = sm.OLS(sig_df[i.__name__][j.name].loc[:ind],x)\n",
    "        result = models.fit()\n",
    "        t_val.append(result.tvalues[0])\n",
    "        p_val.append(result.pvalues[0])\n",
    "#     tp_dict[(i.__name__, j.name, 't')] = t_val\n",
    "    tp_dict[i.__name__, j.name] = p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = pd.DataFrame.from_dict(tp_dict)\n",
    "p_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac847f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp_df.to_excel('tp_vals.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1641ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ps = []\n",
    "for index, row in p_df.iterrows():\n",
    "    l = [1 if i <= 0.1 else 0 for i in row.values ]\n",
    "    small_ps.append(np.sum(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c28735",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(small_ps):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11830905",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df.iloc[-1].to_excel('sig_20181201.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ca448",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.read_excel('frustrated.xlsx', index_col = 0)\n",
    "dfp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(8,8)) \n",
    "dfp['Figure3'].plot()\n",
    "plt.hlines(y = 0, xmin = 0, xmax = 130, colors='r')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('$R^2_{OOS}$', fontsize=18)\n",
    "filename = 'cwy(f4).png'\n",
    "plt.savefig(fname = filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fc1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(8,8)) \n",
    "dfp['b'].plot()\n",
    "plt.hlines(y = 0, xmin = 0, xmax = 130, colors='r')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('$R^2_{OOS}$', fontsize=18)\n",
    "filename = 'co2f4.png'\n",
    "plt.savefig(fname = filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a92d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(8,8)) \n",
    "dfp['c'].plot()\n",
    "plt.hlines(y = 0, xmin = 0, xmax = 130, colors='r')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('$R^2_{OOS}$', fontsize=18)\n",
    "filename = 'co2f5.png'\n",
    "plt.savefig(fname = filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8875a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(8,8)) \n",
    "dfp['d'].plot()\n",
    "plt.hlines(y = 0, xmin = 0, xmax = 130, colors='r')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('$R^2_{OOS}$', fontsize=18)\n",
    "\n",
    "filename = 'co1f3.png'\n",
    "plt.savefig(fname = filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae91fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(8,8)) \n",
    "dfp['e'].plot()\n",
    "plt.hlines(y = 0, xmin = 0, xmax = 130, colors='r')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('$R^2_{OOS}$', fontsize=18)\n",
    "filename = 'co3f3.png'\n",
    "plt.savefig(fname = filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1a30e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfp = pd.read_excel('frustrated.xlsx', index_col = 0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize=(8,8)) \n",
    "dfp['f'].plot()\n",
    "plt.hlines(y = 0, xmin = 0, xmax = 130, colors='r')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('$R^2_{OOS}$', fontsize=18)\n",
    "filename = 'co4f3.png'\n",
    "plt.savefig(fname = filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10500b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "84qx1HrPcx3U",
    "RUf41-q6cx3-",
    "QG4LIQmtcx3_",
    "qnIigwHXcx3_",
    "fL_NT4jIcx4H"
   ],
   "name": "Copy_of_Nonlinear_Model_Estimation(1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
